{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import enum\n",
    "import re\n",
    "import nltk \n",
    "\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verisetinde 50000 adet cümle mevcut.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  One of the other reviewers has mentioned that ...       1\n",
       "1  A wonderful little production. <br /><br />The...       1\n",
       "2  I thought this was a wonderful way to spend ti...       1\n",
       "3  Basically there's a family where a little boy ...       0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veri setinin yüklenmesi ve örnek veri\n",
    "dataset = pd.read_csv(\"data.csv\",delimiter=\";\",header=None,names=[\"Review\",\"Rating\"])\n",
    "print(\"Verisetinde {} adet cümle mevcut.\".format(len(dataset)))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side. \n",
      "\n",
      "one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.<br /><br />the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.<br /><br />it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "#Veri ön işleme\n",
    "#Ön işleme öncesi örnek cümle\n",
    "print(dataset['Review'].values[0],\"\\n\")\n",
    "\n",
    "#büyük harflerin küçük harfe çevrilmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: x.lower())\n",
    "\n",
    "data = dataset['Review'].values.tolist()\n",
    "target = dataset['Rating'].values.tolist()\n",
    "target = np.array(target)\n",
    "\n",
    "#Ön işleme sonrası aynı cümle\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Öncesi: one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.<br /><br />the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.<br /><br />it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "Sonrası: [  27    4    1   79 2102   45 1072   12  100  147   39  307 3184  398\n",
      "  474   26 3195   33   23  203   14   11    6  621   48  596   16   68\n",
      "    7    7    1   86  148   12 3241   68   42 3184   13   92 5398    2\n",
      "  134    4  570   60  268    8  203   36    1  661  139 1740   68   11\n",
      "    6   21    3  119   15    1 7888 2333   38   11  119 2595   54 5911\n",
      "   16 5510    5 1479  376   38  570   92    6 3804    8    1  360  356\n",
      "    4    1  661    7    7    9    6  433 3184   14   12    6    1  358\n",
      "    5    1 6813 2538 1064    9 2711 1421   20  538   32 4636 2468    4\n",
      "    1 1208  117   29    1 7017   25 2970    2  391   34    6   21  299\n",
      "   20    1 4910 7364  538    6  344    5  106 8161 5050 7889 2453    2\n",
      "   51   34  327 9106 7365    2 8697   23  110  225  243    7    7   10\n",
      "   58  131    1  280 1324    4    1  119    6  693    5    1  192   12\n",
      "    9  269  117   79  276  589 3024  834  180 1320 4161   15 2523 1243\n",
      "  834 1443  834  887 3184  149  954  183    1   86  398   10  123  210\n",
      " 3241   68   14   34 1637    9   13 2239   10  413  131   10   13 1592\n",
      "   15    9   18   14   10  287   51   10 1417    3 1280   15 3184    2\n",
      "  189    5    1  299 2046    4 2150  570   21   39  570   18 7658 7154\n",
      " 5010   26 2983   41   15    3 6904  504   20  642    2   76  243   16\n",
      "    9   69 7598  651  710 6904  109  662   82 1208  693    5   65  574\n",
      "    4  920 2021   38 1208  559  147 3184   22  200  426 3819   16   48\n",
      "    6 3314  805 1603   43   22   67   76    8 1228   16  125 4103  486]\n"
     ]
    }
   ],
   "source": [
    "#Cümlelerin içinde geçen kelimelerden 10000 kelimelik bir sözlük oluşturuluyor.\n",
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "#tokenizer.word_index\n",
    "\n",
    "#Cümleler sayılara dönüştürülüyor\n",
    "data_tokens = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "#Cümlelerin önceki ve sonraki hallerinin görüntülenmesi\n",
    "IDX = 0\n",
    "print(\"Öncesi: {}\".format(data[IDX]))\n",
    "print(\"Sonrası: {}\".format(np.array(data_tokens[IDX])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "% 94.53\n"
     ]
    }
   ],
   "source": [
    "#RNN'e girdileri vermeden önce tamamının aynı boyutta olması gerekli. Bu sebeple aşağıdaki matematiksel işlemleri yapıyoruz.\n",
    "\n",
    "num_tokens = np.array([len(tokens) for tokens in data_tokens])\n",
    "#print(np.mean(num_tokens))\n",
    "#print(np.std(num_tokens))\n",
    "#print(np.max(num_tokens))\n",
    "#print(np.min(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens) # np.std = standart sapma\n",
    "max_tokens = int(max_tokens)\n",
    "print(max_tokens)\n",
    "#Verinin ne kadarını bu kapsama aldığımızın ölçülmesi\n",
    "print(\"%\", round(np.sum(num_tokens < max_tokens) / len(num_tokens) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding işlemi. Bulunan uzunluk değerine göre cümlelerin yeniden düzenlenmesi. Kısa olanların başına sıfır eklenmesi.\n",
    "#Uzun olanlardan baştan silme yapılması\n",
    "data_pad = pad_sequences(data_tokens, maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeli oluşuran fonksiyon, KerasClassifier oluşturmak için gerekli\n",
    "def create_model():\n",
    "    #RNN oluşturma, ardışık bir model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #her kelimeye karşılık gelen 50 uzunluğunda bir vektör oluşturulur. (Embedding matrisi)\n",
    "    embedding_size = 50\n",
    "    \n",
    "    #matris kelime sayısı ve embedding büyüklüğünde olacak, yani 10bine 50 uzunluğunda \n",
    "    model.add(Embedding(input_dim=num_words,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_tokens,\n",
    "                        name='embedding_layer'))\n",
    "    #LSTM layerlerinin eklenmesi\n",
    "    # 16 nöronlu LSTM (16 outputlu , return_sequences=True demek output'un tamamını ver demek)\n",
    "    model.add(GRU(units=16, return_sequences=True))\n",
    "    # 8 nöronlu LSTM (8 outputlu , return_sequences=True demek output'un tamamını ver demek)\n",
    "    model.add(GRU(units=8, return_sequences=True))\n",
    "    # 4 nöronlu LSTM (4 outputlu , return_sequences=False yani default değer, tek bir output verecek)\n",
    "    model.add(GRU(units=4))\n",
    "    # Tek bir nörondan oluşan output layer'ı\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #modelin derlenmesi \n",
    "    #iki sınıf olduğu için loss fonksiyonu olarak binary_crossentropy \n",
    "    #modelin başarısını görmek için accuracy metrics\n",
    "    #optimizasyon algoritması\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy','Precision','Recall',])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 9s 51ms/step - loss: 0.3191 - accuracy: 0.8794 - precision: 0.8422 - recall: 0.9273\n",
      "Accuracy=  0.8794000148773193\n",
      "Precision=  0.8422420024871826\n",
      "Recall=  0.9272578954696655\n",
      "F-measure=  0.8827076481939046\n"
     ]
    }
   ],
   "source": [
    "# Modelin değerlendirilmesi\n",
    "seed=0\n",
    "#hold-out \n",
    "x_train, x_test, y_train, y_test = train_test_split(data_pad, target, test_size=0.1, random_state=seed)\n",
    "model=create_model()\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=256, verbose=0)\n",
    "\n",
    "#Evaluate fonksiyonu yalnızca accuracy ve loss değerini döndürür\n",
    "result = model.evaluate(x_test, y_test)\n",
    "\n",
    "import statistics\n",
    "dizi = [result[2],result[3]]\n",
    "\n",
    "print(\"Accuracy= \",result[1])\n",
    "print(\"Precision= \",result[2])\n",
    "print(\"Recall= \",result[3])\n",
    "print(\"F-measure= \",statistics.harmonic_mean(dizi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin oluşturulması\n",
    "# Model eğitimi, bir defa eğitimden geçmesi -> epoch , batch_size -> 256'şar 256'şar beslenecek.\n",
    "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8873  Standart Deviation=  0.00434257987836721\n",
      "Precision=  0.8885179821252491  Standart Deviation=  0.011887093225371426\n",
      "Recall=  0.88611221165833  Standart Deviation=  0.01341785311397468\n",
      "F-measure=  0.8871474438107668  Standart Deviation=  0.003725123099046389\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation\n",
    "scoring = ['accuracy', 'precision','recall','f1']\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "results = cross_validate(model, data_pad, target, cv=kfold, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "print(\"Accuracy= \",results['test_accuracy'].mean(),\" Standart Deviation= \", results['test_accuracy'].std())\n",
    "print(\"Precision= \",results['test_precision'].mean(),\" Standart Deviation= \", results['test_precision'].std())\n",
    "print(\"Recall= \",results['test_recall'].mean(),\" Standart Deviation= \", results['test_recall'].std())\n",
    "print(\"F-measure= \",results['test_f1'].mean(),\" Standart Deviation= \", results['test_f1'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.88666  Standart Deviation=  0.0076488169019790254\n",
      "Precision=  0.8921099895644081  Standart Deviation=  0.01971340983941751\n",
      "Recall=  0.88092  Standart Deviation=  0.028443375327130205\n",
      "F-measure=  0.885877459109498  Standart Deviation=  0.009093335509276561\n"
     ]
    }
   ],
   "source": [
    "#stratified k-fold validation\n",
    "scoring = ['accuracy', 'precision','recall','f1']\n",
    "skfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "results = cross_validate(model, data_pad, target, cv=skfold, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "print(\"Accuracy= \",results['test_accuracy'].mean(),\" Standart Deviation= \", results['test_accuracy'].std())\n",
    "print(\"Precision= \",results['test_precision'].mean(),\" Standart Deviation= \", results['test_precision'].std())\n",
    "print(\"Recall= \",results['test_recall'].mean(),\" Standart Deviation= \", results['test_recall'].std())\n",
    "print(\"F-measure= \",results['test_f1'].mean(),\" Standart Deviation= \", results['test_f1'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#leave-one-out cross validation\n",
    "#Don’t Use LOOCV: Large datasets or costly models to fit(e.g. neural networks).\n",
    "loo = LeaveOneOut()\n",
    "results = cross_val_score(model, data_pad, target, cv=loo, n_jobs=-1)\n",
    "print(results.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
