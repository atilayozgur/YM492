{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Atılay Özgür\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import enum\n",
    "import re\n",
    "import nltk \n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verisetinde 50000 adet cümle mevcut.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  One of the other reviewers has mentioned that ...       1\n",
       "1  A wonderful little production. <br /><br />The...       1\n",
       "2  I thought this was a wonderful way to spend ti...       1\n",
       "3  Basically there's a family where a little boy ...       0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veri setinin yüklenmesi ve örnek veri\n",
    "dataset = pd.read_csv(\"data.csv\",delimiter=\";\",header=None,names=[\"Review\",\"Rating\"])\n",
    "print(\"Verisetinde {} adet cümle mevcut.\".format(len(dataset)))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side. \n",
      "\n",
      "\n",
      "one of the other reviewer have mention that after watch just 1 oz episode you ll be hooked they be right a this be exactly what happen with me br br the first thing that struck me about oz be it brutality and unflinching scene of violence which set in right from the word go trust me this be not show for the faint hearted or timid this show pull no punch with regard to drug sex or violence it be hardcore in the classic use of the word br br it be call oz a that be the nickname give to the oswald maximum security state penitentary it focus mainly on emerald city an experimental section of the prison where all the cell have glass front and face inwards so privacy be not high on the agenda em city be home to many aryan muslim gangsta latino christian italian irish and more so scuffle death stare dodgy dealing and shady agreement be never far away br br would say the main appeal of the show be due to the fact that it go where other show wouldn dare forget pretty picture paint for mainstream audience forget charm forget romance oz doesn mess around the first episode ever saw struck me a so nasty it be surreal couldn say be ready for it but a watch more developed taste for oz and get accustom to the high level of graphic violence not just violence but injustice crooked guard who ll be sell out for nickel inmate who ll kill on order and get away with it well mannered middle class inmate be turn into prison bitch due to their lack of street skill or prison experience watch oz you may become comfortable with what be uncomfortable view thats if you can get in touch with your darker side \n"
     ]
    }
   ],
   "source": [
    "#Veri ön işleme\n",
    "#Ön işleme öncesi örnek cümle\n",
    "print(dataset['Review'].values[0],\"\\n\\n\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatize with POS Tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmaSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    lemma_sentence=[]\n",
    "    for word in token_words:\n",
    "        lemma_sentence.append(wordnet_lemmatizer.lemmatize(word,get_wordnet_pos(word)))\n",
    "        lemma_sentence.append(\" \")\n",
    "    return \"\".join(lemma_sentence)\n",
    "\n",
    "#büyük harflerin küçük harfe çevrilmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: x.lower())\n",
    "\n",
    "# Özel karakterlerin(noktalama işareti vs) çıkartılması\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: re.sub(r\"\\W\", \" \", x))\n",
    "\n",
    "# tek karakterlerin boşluk ile değiştirilmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", x))\n",
    "\n",
    "# en baştan tek kalan karakterlerin çıkartılması\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: re.sub(r\"\\^[a-zA-Z]\\s+\", \" \", x))\n",
    "\n",
    "# Birden fazla boşluğun tek boşlukla değiştirilmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: re.sub(r\"\\s+\", \" \", x))\n",
    "\n",
    "# b öneklerinin silinmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: re.sub(r\"^b\\s+\", \" \", x))\n",
    "\n",
    "#fazladan boşlukların temizlenmesi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: x.strip())\n",
    "\n",
    "#Lemmatization işlemi\n",
    "dataset['Review'] = dataset['Review'].apply(lambda x: lemmaSentence(x))\n",
    "\n",
    "data = dataset['Review'].values.tolist()\n",
    "target = dataset['Rating'].values.tolist()\n",
    "\n",
    "#Ön işleme sonrası aynı cümle\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000 adet cümle eğitim için kullanılacak.\n",
      "5000 adet cümle test için kullanılacak.\n"
     ]
    }
   ],
   "source": [
    "#Cümlelerin eğitim ve test olarak ayrılması %90 Eğitim %10 test\n",
    "ratio = int(len(data) * .90)\n",
    "x_train, y_train = data[:ratio], target[:ratio]\n",
    "y_train = np.array(y_train)\n",
    "x_test, y_test   = data[ratio:], target[ratio:]\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"{} adet cümle eğitim için kullanılacak.\".format(len(x_train)))\n",
    "print(\"{} adet cümle test için kullanılacak.\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Öncesi: one of the other reviewer have mention that after watch just 1 oz episode you ll be hooked they be right a this be exactly what happen with me br br the first thing that struck me about oz be it brutality and unflinching scene of violence which set in right from the word go trust me this be not show for the faint hearted or timid this show pull no punch with regard to drug sex or violence it be hardcore in the classic use of the word br br it be call oz a that be the nickname give to the oswald maximum security state penitentary it focus mainly on emerald city an experimental section of the prison where all the cell have glass front and face inwards so privacy be not high on the agenda em city be home to many aryan muslim gangsta latino christian italian irish and more so scuffle death stare dodgy dealing and shady agreement be never far away br br would say the main appeal of the show be due to the fact that it go where other show wouldn dare forget pretty picture paint for mainstream audience forget charm forget romance oz doesn mess around the first episode ever saw struck me a so nasty it be surreal couldn say be ready for it but a watch more developed taste for oz and get accustom to the high level of graphic violence not just violence but injustice crooked guard who ll be sell out for nickel inmate who ll kill on order and get away with it well mannered middle class inmate be turn into prison bitch due to their lack of street skill or prison experience watch oz you may become comfortable with what be uncomfortable view thats if you can get in touch with your darker side \n",
      "Sonrası: [  23    4    1   79 1135   11  425   10  104   53   39  306 2821  270\n",
      "   18  234    2 2911   28    2  195   13    9    2  610   45  272   16\n",
      "   69    7    7    1   86   97   10 2942   69   42 2821    2    6 4735\n",
      "    3   70    4  556   64  177    8  195   35    1  363   55 1414   69\n",
      "    9    2   20   68   15    1 5637 2146   37 9633    9   68  639   60\n",
      " 1720   16 1116    5  657  382   37  556    6    2 3434    8    1  326\n",
      "  148    4    1  363    7    7    6    2  233 2821   13   10    2    1\n",
      " 6966   92    5    1 5955 2332  565    6  617 1355   19  497   31 4143\n",
      " 1970    4    1 1106  114   25    1 1959   11 1845  909    3  287   34\n",
      "    2   20  263   19    1 3925 2658  497    2  350    5  110 3667 6170\n",
      " 1253  947 2257    3   52   34  304 3757 6314    3 7432 7075    2  113\n",
      "  191  245    7    7   63   76    1  286  843    4    1   68    2  669\n",
      "    5    1  185   10    6   55  114   79   68  569 1559  751  187  348\n",
      " 1552   15 2304  256  751  679  751  782 2821  151  752  190    1   86\n",
      "  270  121  211 2942   69   13   34 1501    6    2 2068  429   76    2\n",
      " 1499   15    6   17   13   53   52 1359 1034   15 2821    3   38 8512\n",
      "    5    1  263  514    4 1338  556   20   39  556   17 5597 6214 1772\n",
      "   32  234    2  956   41   15 4717   32  234  188   19  522    3   38\n",
      "  245   16    6   44 6566  626  616 4717    2  178   82 1106 4602  669\n",
      "    5   67  371    4  654 1273   37 1106  468   53 2821   18  200  269\n",
      " 3441   16   45    2 3024  315 1517   43   18   47   38    8  505   16\n",
      "  123 3658  430]\n"
     ]
    }
   ],
   "source": [
    "#Cümlelerin içinde geçen kelimelerden 10000 kelimelik bir sözlük oluşturuluyor.\n",
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "#tokenizer.word_index\n",
    "\n",
    "#Cümleler sayılara dönüştürülüyor\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "#Cümlelerin önceki ve sonraki hallerinin görüntülenmesi\n",
    "IDX = 0\n",
    "print(\"Öncesi: {}\".format(x_train[IDX]))\n",
    "print(\"Sonrası: {}\".format(np.array(x_train_tokens[IDX])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n",
      "% 94.53\n"
     ]
    }
   ],
   "source": [
    "#RNN'e girdileri vermeden önce tamamının aynı boyutta olması gerekli. Bu sebeple aşağıdaki matematiksel işlemleri yapıyoruz.\n",
    "total_sentences = x_train_tokens + x_test_tokens\n",
    "num_tokens = np.array([len(tokens) for tokens in total_sentences])\n",
    "#print(np.mean(num_tokens))\n",
    "#print(np.std(num_tokens))\n",
    "#print(np.max(num_tokens))\n",
    "#print(np.min(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens) # np.std = standart sapma\n",
    "max_tokens = int(max_tokens)\n",
    "print(max_tokens)\n",
    "#Verinin ne kadarını bu kapsama aldığımızın ölçülmesi\n",
    "print(\"%\", round(np.sum(num_tokens < max_tokens) / len(num_tokens) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding işlemi. Bulunan uzunluk değerine göre cümlelerin yeniden düzenlenmesi. Kısa olanların başına sıfır eklenmesi.\n",
    "#Uzun olanlardan baştan silme yapılması\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\n",
    "x_test_pad  = pad_sequences(x_test_tokens,  maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN oluşturma\n",
    "#ardışık bir model\n",
    "model = Sequential()\n",
    "    \n",
    "#her kelimeye karşılık gelen 50 uzunluğunda bir vektör oluşturulur. (Embedding matrisi)\n",
    "embedding_size = 50\n",
    "    \n",
    "#matris kelime sayısı ve embedding büyüklüğünde olacak, yani 10bine 50 uzunluğunda \n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='embedding_layer'))\n",
    "#LSTM layerlerinin eklenmesi\n",
    "# 16 nöronlu LSTM (16 outputlu , return_sequences=True demek output'un tamamını ver demek)\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "# 8 nöronlu LSTM (8 outputlu , return_sequences=True demek output'un tamamını ver demek)\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "# 4 nöronlu LSTM (4 outputlu , return_sequences=False yani default değer, tek bir output verecek)\n",
    "model.add(GRU(units=4))\n",
    "# Tek bir nörondan oluşan output layer'ı\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#modelin derlenmesi \n",
    "#iki sınıf olduğu için loss fonksiyonu olarak binary_crossentropy \n",
    "#modelin başarısını görmek için accuracy metrics\n",
    "#optimizasyon algoritması\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 539, 50)           500000    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 539, 16)           3264      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 539, 8)            624       \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 4)                 168       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 504,061\n",
      "Trainable params: 504,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Modelin özeti\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "176/176 [==============================] - 86s 460ms/step - loss: 0.6131 - accuracy: 0.6545\n",
      "Epoch 2/5\n",
      "176/176 [==============================] - 82s 467ms/step - loss: 0.2852 - accuracy: 0.8908\n",
      "Epoch 3/5\n",
      "176/176 [==============================] - 83s 471ms/step - loss: 0.2124 - accuracy: 0.9234\n",
      "Epoch 4/5\n",
      "176/176 [==============================] - 82s 468ms/step - loss: 0.1774 - accuracy: 0.9400\n",
      "Epoch 5/5\n",
      "176/176 [==============================] - 82s 467ms/step - loss: 0.1690 - accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1911c0d2970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model eğitimi, bir defa eğitimden geçmesi -> epoch , batch_size -> 256'şar 256'şar beslenecek.\n",
    "model.fit(x_train_pad, y_train, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 9s 51ms/step - loss: 0.2845 - accuracy: 0.8926\n",
      "Test verisindeki 5000 adet cümleden 4462 tanesi doğru bilindi.\n"
     ]
    }
   ],
   "source": [
    "#Evaluate fonksiyonu yalnızca accuracy ve loss değerini döndürür\n",
    "result = model.evaluate(x_test_pad, y_test)\n",
    "\n",
    "num_true_sentence = int(len(x_test) * result[1])\n",
    "print(\"Test verisindeki {} adet cümleden {} tanesi doğru bilindi.\".format(len(x_test), num_true_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle: what enjoy most in this film be the scenery of corfu be greek adore my country and like the flatter director point of view base on true story during the year when greece be struggle to stand on her own two foot through war nazi and hardship an italian soldier and greek girl fall in love but the time be hard and they have lot of sacrifice to make nicholas cage look great in uniform give passionate account of this unfulfilled in the begin love adore christian bale play mandras the heroine husband to be he look very very good a greek his personality match the one of the greek patriot true fighter in there or what one of the movie would like to buy and keep it in my collection for ever  \n",
      "Asıl Etiket: 1 \n",
      "Üretilen Etiket: 1\n"
     ]
    }
   ],
   "source": [
    "#tek tek cümlelerin sonuçlarını görmek için predict metodu kullanılması\n",
    "y_pred = model.predict(x_test_pad)\n",
    "\n",
    "#Her cümle için çıktı 0 ile 1 arasındadır. 0 olumsuz 1 olumlu anlamındadır. \n",
    "#0.5 üzerini olumlu altını olumsuz olarak işaretleyelim.\n",
    "y_pred = np.array([1 if p>0.5 else 0 for p in y_pred])\n",
    "\n",
    "#Bir örnek üzerinde inceleyelim.\n",
    "IDX = 0\n",
    "sentence = x_test[IDX]\n",
    "real_rate = y_test[IDX]\n",
    "predicted_rate = y_pred[IDX]\n",
    "\n",
    "print(\"Cümle: {} \\nAsıl Etiket: {} \\nÜretilen Etiket: {}\".format(sentence, real_rate, predicted_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      2530\n",
      "           1       0.89      0.89      0.89      2470\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy değeri hariç precision,recall ve f-measure değerlerine bakalım.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
